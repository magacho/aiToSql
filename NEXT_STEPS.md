# ğŸš€ PrÃ³ximos Passos - aiToSql MCP Server

## Status Atual

âœ… **v0.1.0 publicada** (28/Out/2024)  
âœ… **31 testes passando (100%)**  
âœ… **Cobertura: 74%**  
âœ… **TokenizaÃ§Ã£o local implementada**  
âœ… **Teste E2E completo (jornada full-stack)**  
ğŸ”„ **Em desenvolvimento: v0.2.0**

---

## ğŸ¯ Objetivo da v0.2.0: IntegraÃ§Ã£o com LLMs Reais

Atualmente, temos **estimativas** de tokens e custos baseadas em aproximaÃ§Ãµes (1 token â‰ˆ 4 chars). 

**Precisamos integrar com APIs reais de LLMs para:**
1. âœ¨ **Gerar SQL a partir de linguagem natural** (Text-to-SQL)
2. ğŸ¯ **TokenizaÃ§Ã£o precisa** (usando contadores reais dos LLMs)
3. ğŸ’° **Custos reais** de API tracking
4. ğŸ§  **Query explanation** (SQL â†’ Linguagem Natural)
5. ğŸ“Š **Query optimization suggestions**

---

## ğŸ“… Cronograma v0.2.0 (3-4 Semanas)

### ğŸ¤– Semana 1-2: IntegraÃ§Ã£o com APIs de LLMs

#### 1. OpenAI GPT-4 Integration (5 dias) ğŸ”´ CRÃTICO

**Objetivos:**
- Implementar client HTTP para OpenAI API
- TokenizaÃ§Ã£o real usando tiktoken-java (ou equivalente)
- GeraÃ§Ã£o de SQL a partir de linguagem natural
- Cache de respostas para economizar custos
- Tracking de custos real (nÃ£o estimado)

**Tasks:**
```bash
# Branch de trabalho
git checkout -b feature/openai-integration

# Adicionar dependÃªncia no pom.xml
# <dependency>
#   <groupId>com.theokanning.openai-gpt3-java</groupId>
#   <artifactId>service</artifactId>
#   <version>0.18.2</version>
# </dependency>

# Criar arquivos:
# - src/main/java/com/magacho/aiToSql/llm/LLMProvider.java (interface)
# - src/main/java/com/magacho/aiToSql/llm/OpenAIProvider.java (impl)
# - src/main/java/com/magacho/aiToSql/service/LLMService.java
# - src/test/java/com/magacho/aiToSql/llm/OpenAIProviderTest.java
```

**EntregÃ¡veis:**
- [ ] Interface `LLMProvider` com mÃ©todos:
  - `generateSQL(String naturalLanguage, String schemaContext)`
  - `explainQuery(String sqlQuery)`
  - `countTokens(String text)`
  - `estimateCost(int tokens)`
- [ ] `OpenAIProvider` implementado
- [ ] `LLMService` para orquestraÃ§Ã£o
- [ ] Testes unitÃ¡rios (mock da API)
- [ ] Testes de integraÃ§Ã£o (chamada real, opcional)
- [ ] DocumentaÃ§Ã£o: `docs/OPENAI_SETUP.md`

**ConfiguraÃ§Ã£o (application.properties):**
```properties
# OpenAI Configuration
llm.provider=openai
llm.openai.api-key=${OPENAI_API_KEY}
llm.openai.model=gpt-4-turbo-preview
llm.openai.max-tokens=2000
llm.openai.temperature=0.0
```

---

#### 2. Claude, Gemini e Ollama (5 dias)

**Claude (Anthropic)** - 2 dias
- [ ] `ClaudeProvider` implementation
- [ ] Testes de integraÃ§Ã£o
- [ ] ComparaÃ§Ã£o de performance vs GPT-4

**Gemini (Google)** - 1 dia
- [ ] `GeminiProvider` implementation
- [ ] Testes bÃ¡sicos

**Ollama (Local)** - 2 dias
- [ ] `OllamaProvider` implementation
- [ ] Suporte a Llama 3, Mistral, CodeLlama
- [ ] Testes locais (sem custo)
- [ ] DocumentaÃ§Ã£o de setup do Ollama

**ConfiguraÃ§Ã£o:**
```properties
# llm.provider=openai|claude|gemini|ollama

# Claude
llm.claude.api-key=${ANTHROPIC_API_KEY}
llm.claude.model=claude-3-5-sonnet-20241022

# Gemini
llm.gemini.api-key=${GOOGLE_API_KEY}
llm.gemini.model=gemini-1.5-pro

# Ollama (local, sem API key)
llm.ollama.base-url=http://localhost:11434
llm.ollama.model=llama3.2
```

---

### ğŸ§  Semana 3: Text-to-SQL Intelligence

#### 3. Nova Ferramenta MCP: `naturalLanguageQuery` (4 dias) ğŸ”´ CRÃTICO

**Objetivo:** Permitir que usuÃ¡rios faÃ§am perguntas em linguagem natural e recebam SQL + resultados.

**Flow:**
```
1. UsuÃ¡rio envia: "Quais sÃ£o os 10 maiores clientes por valor de compras?"
2. MCP chama getSchemaStructure (para contexto)
3. MCP chama LLMService.generateSQL(pergunta, schema)
4. LLM retorna: "SELECT c.name, SUM(o.total) FROM customers c..."
5. MCP valida e executa SQL
6. MCP retorna: SQL gerado + resultados + custo da operaÃ§Ã£o
```

**Tasks:**
- [ ] Criar `NaturalLanguageQueryService`
- [ ] Adicionar ferramenta `naturalLanguageQuery` no `McpToolsRegistry`
- [ ] Prompt engineering:
  ```
  System: VocÃª Ã© um especialista em SQL. Dado o schema:
  {schema}
  
  Gere uma query SQL vÃ¡lida para a pergunta:
  {question}
  
  Retorne APENAS o SQL, sem explicaÃ§Ãµes.
  ```
- [ ] ValidaÃ§Ã£o de SQL gerado (mesmo processo de `secureDatabaseQuery`)
- [ ] Refinamento iterativo (se SQL invÃ¡lido, retry com erro como contexto)
- [ ] Testes E2E com perguntas reais

**ParÃ¢metros:**
```json
{
  "name": "naturalLanguageQuery",
  "description": "Execute queries usando linguagem natural",
  "inputSchema": {
    "type": "object",
    "properties": {
      "question": {
        "type": "string",
        "description": "Pergunta em linguagem natural"
      },
      "maxRows": {
        "type": "integer",
        "default": 100
      }
    },
    "required": ["question"]
  }
}
```

**Retorno:**
```json
{
  "content": [{
    "type": "text",
    "text": "{
      \"generatedSQL\": \"SELECT ...\",
      \"results\": [...],
      \"rowCount\": 10,
      \"llmProvider\": \"openai\",
      \"llmModel\": \"gpt-4-turbo\",
      \"tokensUsed\": 1250,
      \"costUSD\": 0.0375
    }"
  }]
}
```

---

#### 4. Nova Ferramenta: `explainQuery` (2 dias)

**Objetivo:** Receber SQL e retornar explicaÃ§Ã£o em linguagem natural.

**Exemplo:**
```
Input: SELECT c.name, SUM(o.total) FROM customers c JOIN orders o ON c.id = o.customer_id GROUP BY c.name ORDER BY SUM(o.total) DESC LIMIT 10

Output: "Esta consulta busca os 10 clientes que mais gastaram. 
Ela junta a tabela de clientes com a tabela de pedidos,
soma o total de pedidos de cada cliente, e retorna os 10 maiores valores."
```

**Tasks:**
- [ ] Criar ferramenta `explainQuery`
- [ ] Prompt engineering para explicaÃ§Ãµes claras
- [ ] Testes com queries complexas
- [ ] DocumentaÃ§Ã£o

---

#### 5. Nova Ferramenta: `suggestQueryOptimizations` (2 dias)

**Objetivo:** Analisar query e sugerir melhorias.

**Tasks:**
- [ ] Integrar com `EXPLAIN` do banco
- [ ] LLM analisa o plan e sugere:
  - Ãndices faltantes
  - Reescrita de query
  - Hints de performance
- [ ] Testes
- [ ] DocumentaÃ§Ã£o

---

### ğŸ’° Semana 4: Cost Dashboard e Analytics

#### 6. Enhanced Cost Tracking (3 dias)

**Objetivo:** Melhorar tracking de custos reais.

**Tasks:**
- [ ] Atualizar `TokenizationMetrics` para usar custos reais (nÃ£o estimados)
- [ ] Breakdown por LLM provider
- [ ] Endpoint `/mcp/analytics/cost?from=X&to=Y&provider=openai`
- [ ] ComparaÃ§Ã£o de custos entre providers
- [ ] Alertas de threshold (exemplo: se custo/dia > $10, avisar)

---

#### 7. Simple Web Dashboard (2 dias)

**Objetivo:** UI simples para visualizar custos e mÃ©tricas.

**Tasks:**
- [ ] Criar `src/main/resources/static/dashboard.html`
- [ ] Chart.js para grÃ¡ficos
- [ ] Endpoint `/mcp/dashboard` serve HTML estÃ¡tico
- [ ] GrÃ¡ficos:
  - Custos ao longo do tempo
  - Breakdown por ferramenta
  - Breakdown por LLM provider
  - Top queries por custo
  - Cache hit rate

**Tech Stack:**
- HTML + CSS (simples, sem framework)
- Chart.js (via CDN)
- Fetch API para buscar dados de `/mcp/metrics` e `/mcp/analytics/cost`

---

#### 8. Usage Reporting (2 dias)

**Tasks:**
- [ ] Endpoint `/mcp/reports/usage?from=X&to=Y`
- [ ] Export CSV/JSON
- [ ] RelatÃ³rios automÃ¡ticos (opcional: email/webhook)
- [ ] DocumentaÃ§Ã£o

---

## ğŸ“Š MÃ©tricas de Sucesso da v0.2.0

### CritÃ©rios de AceitaÃ§Ã£o:
- âœ… IntegraÃ§Ã£o com no mÃ­nimo 2 LLM providers (OpenAI + Ollama)
- âœ… Ferramenta `naturalLanguageQuery` funcional
- âœ… Text-to-SQL accuracy > 80% (testar com 20 perguntas padrÃ£o)
- âœ… Custos reais sendo trackados (nÃ£o estimados)
- âœ… Dashboard web funcional
- âœ… Cobertura de testes â‰¥ 78%
- âœ… Todos os testes passando
- âœ… DocumentaÃ§Ã£o atualizada

### KPIs:
| MÃ©trica | v0.1.0 | Meta v0.2.0 |
|---------|--------|-------------|
| Cobertura | 74% | 78% |
| Testes | 31 | ~40 |
| Ferramentas MCP | 4 | 7 |
| LLM Providers | 0 | 4 |
| Tempo mÃ©dio | <100ms | <150ms* |
| Accuracy Text-to-SQL | N/A | >80% |

\* *Inclui latÃªncia de chamadas LLM*

---

## ğŸ”„ Processo de Desenvolvimento

### Workflow Recomendado:

```bash
# 1. Criar branch feature
git checkout -b feature/openai-integration

# 2. Desenvolvimento TDD
# - Escrever testes primeiro
# - Implementar funcionalidade
# - Refatorar

# 3. Executar testes localmente
mvn clean test

# 4. Verificar cobertura
mvn jacoco:report
firefox target/site/jacoco/index.html

# 5. Commit incremental
git add .
git commit -m "feat: adicionar OpenAI provider com testes"

# 6. Push e PR
git push origin feature/openai-integration
# Criar PR no GitHub

# 7. Merge apÃ³s revisÃ£o
# CI/CD executa testes automaticamente

# 8. ApÃ³s merge, branch main estÃ¡ atualizada
git checkout main
git pull origin main
```

---

## ğŸ“š DocumentaÃ§Ã£o a Criar/Atualizar

### Novos Documentos:
- [ ] `docs/OPENAI_SETUP.md` - Setup do OpenAI API
- [ ] `docs/CLAUDE_SETUP.md` - Setup do Anthropic Claude
- [ ] `docs/GEMINI_SETUP.md` - Setup do Google Gemini
- [ ] `docs/OLLAMA_SETUP.md` - Setup do Ollama local
- [ ] `docs/TEXT_TO_SQL.md` - Como usar Text-to-SQL
- [ ] `docs/LLM_COMPARISON.md` - ComparaÃ§Ã£o de providers
- [ ] `docs/COST_OPTIMIZATION.md` - Como reduzir custos

### Atualizar:
- [ ] `README.md` - Adicionar seÃ§Ã£o de LLM integration
- [ ] `QUICKSTART.md` - Adicionar exemplos de Text-to-SQL
- [ ] `ROADMAP.md` - Marcar v0.2.0 como em progresso
- [ ] `IMPLEMENTATION_SUMMARY.md` - Adicionar arquitetura de LLMs

---

## ğŸ§ª Testes Importantes

### Testes de IntegraÃ§Ã£o LLM:
```java
@Test
void testOpenAI_GenerateSQL_SimpleQuery() {
    String nl = "Liste os 5 clientes mais recentes";
    String sql = llmService.generateSQL(nl, schemaContext);
    
    assertTrue(sql.toUpperCase().contains("SELECT"));
    assertTrue(sql.toUpperCase().contains("LIMIT 5"));
}

@Test
void testOpenAI_TokenCounting() {
    String text = "Hello, world!";
    int tokens = openAIProvider.countTokens(text);
    
    assertTrue(tokens > 0);
    assertTrue(tokens < 10); // ~3-4 tokens esperados
}

@Test
void testCostTracking_RealAPI() {
    String nl = "Mostre todos os produtos";
    QueryResult result = naturalLanguageQueryService.execute(nl, 100);
    
    assertNotNull(result.getTokenizationMetrics());
    assertTrue(result.getTokenizationMetrics().getCostUSD() > 0);
}
```

### Teste E2E Completo:
```java
@Test
void testFullJourney_NaturalLanguageToResults() {
    // 1. Schema understanding
    String schema = schemaService.getSchemaInfo().schemaPrompt();
    
    // 2. Natural language query
    String question = "Quais os 10 produtos mais vendidos no Ãºltimo mÃªs?";
    
    // 3. Generate SQL via LLM
    String sql = llmService.generateSQL(question, schema);
    
    // 4. Validate SQL
    assertTrue(sql.toUpperCase().startsWith("SELECT"));
    
    // 5. Execute query
    QueryResult result = queryService.executeQuery(sql, 10);
    
    // 6. Verify results
    assertNotNull(result);
    assertTrue(result.getRowCount() <= 10);
    
    // 7. Verify tokenization
    assertNotNull(result.getTokenizationMetrics());
    assertTrue(result.getTokenizationMetrics().getEstimatedTokens() > 0);
    assertTrue(result.getTokenizationMetrics().getCostUSD() > 0);
}
```

---

## âš ï¸ Riscos e MitigaÃ§Ãµes

| Risco | Impacto | MitigaÃ§Ã£o |
|-------|---------|-----------|
| **Custo alto de APIs LLM** | Alto | Cache agressivo, usar Ollama para dev, rate limiting |
| **Accuracy baixa do Text-to-SQL** | MÃ©dio | Prompt engineering, refinamento iterativo, feedback loop |
| **LatÃªncia de APIs LLM** | MÃ©dio | Cache, async processing, timeout configurÃ¡vel |
| **DependÃªncia de APIs externas** | Alto | Fallback para Ollama local, retry logic, circuit breaker |
| **Complexidade de integraÃ§Ã£o** | MÃ©dio | Abstrair em interface, testes mocados primeiro |

---

## ğŸ’¡ Dicas para Desenvolvimento

### 1. ComeÃ§ar com Mocks
```java
// Implementar MockLLMProvider primeiro
// Permite testar sem gastar dinheiro em APIs
public class MockLLMProvider implements LLMProvider {
    @Override
    public String generateSQL(String nl, String schema) {
        return "SELECT * FROM customers LIMIT 10"; // Resposta fixa
    }
}
```

### 2. Usar VariÃ¡veis de Ambiente
```bash
# .env (nÃ£o commitado)
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
GOOGLE_API_KEY=AI...
```

### 3. Cache Agressivo
```properties
# Cache de respostas LLM por 24h
spring.cache.cache-names=schema-info,llm-responses
spring.cache.caffeine.spec=maximumSize=100,expireAfterWrite=24h
```

### 4. Monitoring de Custos
```java
// Alert quando custo diÃ¡rio exceder threshold
if (dailyCost > MAX_DAILY_COST) {
    log.error("Daily cost exceeded: ${}", dailyCost);
    // Enviar email/Slack/etc
}
```

---

## ğŸ“… Checklist Final para Release v0.2.0

Antes de criar a release:

- [ ] Todos os testes passando (â‰¥ 40 testes)
- [ ] Cobertura â‰¥ 78%
- [ ] IntegraÃ§Ã£o com no mÃ­nimo 2 LLM providers
- [ ] Ferramenta `naturalLanguageQuery` funcional
- [ ] Text-to-SQL accuracy â‰¥ 80%
- [ ] Dashboard web funcional
- [ ] DocumentaÃ§Ã£o atualizada
- [ ] Changelog atualizado
- [ ] Performance metrics dentro do esperado
- [ ] Testes E2E passando
- [ ] Build do Maven sem erros
- [ ] Criar tag `REL-0.2.0`
- [ ] Push para GitHub
- [ ] Verificar workflow CI/CD
- [ ] Publicar release notes

---

## ğŸ¯ Depois da v0.2.0

ApÃ³s completar v0.2.0, as prÃ³ximas prioridades sÃ£o:

1. **v0.3.0 - SeguranÃ§a** (Auth, Rate Limiting, Audit)
2. **v0.4.0 - Performance** (Redis, Async, Multi-tenancy)
3. **v0.5.0 - Observabilidade** (Prometheus, Grafana)
4. **v0.6.0 - Developer Experience** (SDKs, CLI, Web UI)

Veja [ROADMAP.md](ROADMAP.md) para detalhes completos.

---

## ğŸ“ Precisa de Ajuda?

- **Roadmap Completo**: [ROADMAP.md](ROADMAP.md)
- **Issues**: https://github.com/magacho/aiToSql/issues
- **Discussions**: https://github.com/magacho/aiToSql/discussions
- **Mantenedor**: @magacho

---

**Boa sorte com o desenvolvimento da v0.2.0! ğŸš€**

**PrÃ³xima revisÃ£o**: ApÃ³s merge do primeiro PR de LLM integration  
**Data**: 28 de Outubro de 2024

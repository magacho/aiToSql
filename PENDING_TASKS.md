# üìã Tarefas Pendentes - aiToSql MCP Server

**Data**: 29 de Outubro de 2024  
**Status Atual**: v0.2.0 (Docker publicado)  
**Pr√≥xima Release**: v0.3.0

---

## ‚úÖ Completado

### Fase 1 - MVP (v0.1.0)
- ‚úÖ Protocolo MCP JSON-RPC 2.0
- ‚úÖ 4 ferramentas MCP implementadas
- ‚úÖ Sistema de tokeniza√ß√£o
- ‚úÖ M√©tricas de performance
- ‚úÖ Testes automatizados (74% cobertura)
- ‚úÖ CI/CD com GitHub Actions

### Fase 2.1 - Docker (v0.2.0)
- ‚úÖ Dockerfile multi-stage otimizado
- ‚úÖ Configura√ß√£o via vari√°veis de ambiente
- ‚úÖ Suporte multi-database (PostgreSQL, MySQL, SQL Server)
- ‚úÖ Docker Compose para testes locais
- ‚úÖ GitHub Actions para build e publica√ß√£o
- ‚úÖ Multi-architecture (amd64, arm64)
- ‚úÖ Documenta√ß√£o completa

---

## üéØ Fase Atual - v0.3.0: Integra√ß√£o com LLMs Reais

**Objetivo**: Conectar com APIs de LLMs para Text-to-SQL e an√°lise inteligente  
**Prioridade**: üî¥ CR√çTICA  
**Prazo Estimado**: 3-4 semanas  
**Meta de Cobertura**: 82%

### 3.1 Integra√ß√£o com APIs de LLMs ü§ñ
**Status**: ‚è≥ PLANEJADO  
**Estimativa**: 2 semanas

#### Tarefas:

- [ ] **OpenAI GPT-4 Integration** (5 dias)
  - [ ] Implementar client para API OpenAI
  - [ ] Tokeniza√ß√£o real usando tiktoken equivalente (Java)
  - [ ] Gera√ß√£o de SQL a partir de linguagem natural
  - [ ] Cache de respostas para reduzir custos
  - [ ] Tracking de custos real (n√£o estimado)
  - [ ] Testes de integra√ß√£o (mock + real)
  - [ ] Configura√ß√£o via properties: `openai.api-key`, `openai.model`
  
- [ ] **Anthropic Claude Integration** (3 dias)
  - [ ] Client para API Claude
  - [ ] Suporte a Claude 3.5 Sonnet
  - [ ] Compara√ß√£o de performance vs GPT-4
  - [ ] Testes de integra√ß√£o
  - [ ] Configura√ß√£o via properties: `claude.api-key`, `claude.model`
  
- [ ] **Google Gemini Integration** (2 dias)
  - [ ] Client para API Gemini
  - [ ] Suporte a Gemini Pro/Ultra
  - [ ] Testes de integra√ß√£o
  - [ ] Configura√ß√£o via properties: `gemini.api-key`, `gemini.model`
  
- [ ] **Ollama Local LLM** (2 dias)
  - [ ] Integra√ß√£o com Ollama para modelos locais
  - [ ] Suporte a Llama 3, Mistral, CodeLlama
  - [ ] Sem custos de API
  - [ ] Testes locais
  - [ ] Configura√ß√£o via properties: `ollama.base-url`, `ollama.model`

#### Arquitetura:

```java
// Interface abstrata
public interface LLMProvider {
    String generateSQL(String naturalLanguageQuery, String schemaContext);
    String explainQuery(String sqlQuery);
    TokenizationMetrics getTokenMetrics();
}

// Implementa√ß√µes
- OpenAIProvider implements LLMProvider
- ClaudeProvider implements LLMProvider  
- GeminiProvider implements LLMProvider
- OllamaProvider implements LLMProvider

// Service Layer
@Service
public class LLMService {
    private final Map<String, LLMProvider> providers;
    
    public String generateSQL(String query, String schema, String provider) {
        return providers.get(provider).generateSQL(query, schema);
    }
}
```

#### Configura√ß√£o (application.properties):

```properties
# LLM Provider Selection
llm.provider=openai  # openai|claude|gemini|ollama

# OpenAI
llm.openai.api-key=${OPENAI_API_KEY}
llm.openai.model=gpt-4-turbo-preview
llm.openai.base-url=https://api.openai.com/v1

# Claude
llm.claude.api-key=${CLAUDE_API_KEY}
llm.claude.model=claude-3-5-sonnet-20241022
llm.claude.base-url=https://api.anthropic.com/v1

# Gemini
llm.gemini.api-key=${GEMINI_API_KEY}
llm.gemini.model=gemini-pro
llm.gemini.base-url=https://generativelanguage.googleapis.com/v1

# Ollama (local)
llm.ollama.base-url=http://localhost:11434
llm.ollama.model=llama3
```

#### Deliverables:
- ‚úÖ Interface `LLMProvider`
- ‚úÖ 4 implementa√ß√µes concretas
- ‚úÖ Service layer: `LLMService` com sele√ß√£o de provider
- ‚úÖ Configura√ß√£o via properties
- ‚úÖ Testes unit√°rios + integra√ß√£o (mock)
- ‚úÖ Documenta√ß√£o de setup para cada provider

**Impacto na Cobertura**: +2%

---

### 3.2 Text-to-SQL Intelligence üß†
**Status**: ‚è≥ PLANEJADO  
**Estimativa**: 1.5 semanas

#### Tarefas:

- [ ] **Nova Ferramenta MCP: `naturalLanguageQuery`** (4 dias)
  - [ ] Parser de inten√ß√£o de usu√°rio
  - [ ] Gera√ß√£o de SQL usando LLM + contexto de schema
  - [ ] Prompt engineering otimizado para SQL generation
  - [ ] Valida√ß√£o e sanitiza√ß√£o de SQL gerado
  - [ ] Refinamento iterativo (se SQL inv√°lido, retry com erro)
  - [ ] Testes com diversos tipos de perguntas
  - [ ] Documenta√ß√£o de accuracy
  
- [ ] **Nova Ferramenta MCP: `explainQuery`** (2 dias)
  - [ ] Recebe SQL, retorna explica√ß√£o em linguagem natural
  - [ ] Usa LLM para gerar explica√ß√£o clara
  - [ ] √ötil para documenta√ß√£o autom√°tica
  - [ ] Testes com queries complexas
  
- [ ] **Query Optimization Suggestions** (2 dias)
  - [ ] Nova ferramenta: `suggestQueryOptimizations`
  - [ ] LLM analisa EXPLAIN plan do banco
  - [ ] Sugest√µes de √≠ndices, reescrita, hints
  - [ ] Testes com queries lentas

#### Exemplo de Implementa√ß√£o:

```java
@Service
public class TextToSQLService {
    
    private final LLMService llmService;
    private final SchemaService schemaService;
    private final QueryService queryService;
    
    public QueryResult naturalLanguageQuery(String question, String provider) {
        // 1. Obter contexto do schema
        String schema = schemaService.getSchemaStructure();
        
        // 2. Gerar SQL via LLM
        String sql = llmService.generateSQL(question, schema, provider);
        
        // 3. Validar SQL
        if (!isValidSQL(sql)) {
            throw new IllegalArgumentException("SQL inv√°lido gerado");
        }
        
        // 4. Executar query
        List<Map<String, Object>> results = queryService.executeSearch(sql);
        
        // 5. Gerar explica√ß√£o
        String explanation = llmService.explainQuery(sql);
        
        return new QueryResult(sql, results, explanation);
    }
    
    public String explainQuery(String sql) {
        return llmService.explainQuery(sql);
    }
    
    public List<String> suggestOptimizations(String sql) {
        // Executar EXPLAIN no banco
        String explainPlan = queryService.getExplainPlan(sql);
        
        // LLM analisa e sugere
        return llmService.suggestOptimizations(sql, explainPlan);
    }
}
```

#### Novos Endpoints MCP:

```json
{
  "jsonrpc": "2.0",
  "method": "tools/call",
  "params": {
    "name": "naturalLanguageQuery",
    "arguments": {
      "question": "Quais s√£o os 10 clientes com mais pedidos?",
      "provider": "openai",
      "maxRows": 10
    }
  }
}
```

#### Deliverables:
- ‚úÖ 3 novas ferramentas MCP
- ‚úÖ Prompt templates versionados (v1.0)
- ‚úÖ Endpoint `/mcp/tools/call` atualizado
- ‚úÖ Testes E2E de Text-to-SQL
- ‚úÖ Documenta√ß√£o de prompts e accuracy
- ‚úÖ Compara√ß√£o de accuracy entre LLMs

**Impacto na Cobertura**: +2%

---

### 3.3 Cost Tracking Dashboard üí∞
**Status**: ‚è≥ PLANEJADO  
**Estimativa**: 1 semana

#### Tarefas:

- [ ] **Enhanced Cost Analytics** (3 dias)
  - [ ] Endpoint `/mcp/analytics/cost`
  - [ ] Breakdown por ferramenta, LLM provider, per√≠odo
  - [ ] Compara√ß√£o de custos: OpenAI vs Claude vs Gemini
  - [ ] Alertas de threshold de custo (configur√°vel)
  - [ ] Export CSV/JSON
  
- [ ] **Simple Web Dashboard** (2 dias)
  - [ ] HTML + Chart.js simples (sem framework pesado)
  - [ ] Endpoint `/mcp/dashboard` serve p√°gina est√°tica
  - [ ] Gr√°ficos de custos ao longo do tempo
  - [ ] Top queries por custo
  - [ ] Cache hit rate visualization
  
- [ ] **Usage Reporting** (2 dias)
  - [ ] Relat√≥rios autom√°ticos (JSON)
  - [ ] Endpoint `/mcp/reports/usage?from=X&to=Y`
  - [ ] Integra√ß√£o com billing systems (webhook opcional)

#### Exemplo de Response:

```json
{
  "period": {
    "from": "2024-10-01",
    "to": "2024-10-31"
  },
  "totalCost": {
    "usd": 125.50
  },
  "breakdown": {
    "openai": {
      "calls": 1234,
      "tokens": 1500000,
      "cost": 75.00
    },
    "claude": {
      "calls": 567,
      "tokens": 800000,
      "cost": 40.00
    },
    "gemini": {
      "calls": 234,
      "tokens": 300000,
      "cost": 10.50
    }
  },
  "topExpensiveQueries": [
    {
      "query": "An√°lise complexa de vendas...",
      "cost": 5.25,
      "tokens": 35000
    }
  ]
}
```

#### Deliverables:
- ‚úÖ Enhanced metrics endpoints
- ‚úÖ Simple web dashboard (HTML + Chart.js)
- ‚úÖ Automated reporting
- ‚úÖ Testes de analytics
- ‚úÖ Documenta√ß√£o de uso

**Impacto na Cobertura**: +0%

---

## üîí Fase Futura - v0.4.0: Seguran√ßa e Produ√ß√£o

**Objetivo**: Tornar o servidor production-ready  
**Prioridade**: üü° ALTA  
**Prazo Estimado**: 2-3 semanas  
**Status**: üîÆ FUTURO  
**Meta de Cobertura**: 86%

### Resumo:
- Autentica√ß√£o e Autoriza√ß√£o (API Key + JWT)
- Rate Limiting e Cost-Based Throttling
- Audit Logging e Compliance (LGPD/GDPR)

---

## ‚ö° Fase Futura - v0.5.0: Performance e Escalabilidade

**Objetivo**: Otimizar para alta carga  
**Prioridade**: üü° M√âDIA  
**Prazo Estimado**: 2-3 semanas  
**Status**: üîÆ FUTURO  
**Meta de Cobertura**: 90%

### Resumo:
- Cache Distribu√≠do (Redis)
- Async Processing (WebSocket streaming)
- Multi-Tenancy

---

## üìä Fase Futura - v0.6.0: Observabilidade Avan√ßada

**Objetivo**: Monitoring e metrics production-grade  
**Prioridade**: üü¢ M√âDIA  
**Prazo Estimado**: 1-2 semanas  
**Status**: üîÆ FUTURO  
**Meta de Cobertura**: 92%

### Resumo:
- Prometheus & Grafana
- Distributed Tracing (Zipkin/Jaeger)
- Alertas e SLOs

---

## üé® Fase Futura - v0.7.0: Developer Experience

**Objetivo**: SDKs, CLI e Web UI  
**Prioridade**: üîµ BAIXA  
**Prazo Estimado**: 3-4 semanas  
**Status**: üîÆ FUTURO  
**Meta de Cobertura**: 94%

### Resumo:
- SDKs (Python, TypeScript/JS, Go)
- CLI Tool
- Web Dashboard React
- Documenta√ß√£o interativa (Swagger UI)

---

## üéØ Timeline

```
Nov 2024 üîÑ v0.3.0: Integra√ß√£o LLMs
‚îÇ   ‚îú‚îÄ Week 1: OpenAI + Claude
‚îÇ   ‚îú‚îÄ Week 2: Gemini + Ollama
‚îÇ   ‚îú‚îÄ Week 3: Text-to-SQL tools
‚îÇ   ‚îî‚îÄ Week 4: Cost dashboard

Dec 2024 ‚è≥ v0.4.0: Seguran√ßa
‚îÇ   ‚îú‚îÄ Week 1: Auth + RBAC
‚îÇ   ‚îú‚îÄ Week 2: Rate limiting
‚îÇ   ‚îî‚îÄ Week 3: Audit logging

Jan 2025 üîÆ v0.5.0: Performance
Feb 2025 üîÆ v0.6.0: Observabilidade
Mar 2025 üîÆ v0.7.0: Developer Experience
```

---

## üìà M√©tricas de Sucesso

### v0.3.0 üéØ METAS
- üéØ Cobertura: 82%
- üéØ Integra√ß√£o com 4 LLM providers
- üéØ Text-to-SQL accuracy > 80%
- üéØ Tempo m√©dio < 2s (inclui chamadas LLM)
- üéØ Cost tracking real implementado
- üéØ Dashboard web funcional

---

## üöÄ Pr√≥ximos Passos Imediatos

1. **Escolher LLM Provider Inicial** (Sugest√£o: OpenAI ou Ollama)
2. **Implementar Interface LLMProvider**
3. **Implementar OpenAI Client**
4. **Criar Tool `naturalLanguageQuery`**
5. **Adicionar testes de integra√ß√£o**
6. **Documentar setup e exemplos**

---

**Nota**: Kubernetes deployment (Fase 2.2) foi **removido** do roadmap conforme solicita√ß√£o do usu√°rio.

**√öltima Atualiza√ß√£o**: 29 de Outubro de 2024  
**Vers√£o do Documento**: 1.0
